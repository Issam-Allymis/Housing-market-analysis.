{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression\n",
    "## Objectives\n",
    "* Fit and evaluate a regression model for predicting property sale prices using our training and testing datasets.\n",
    "## Inputs\n",
    "* outputs\\datasets\\cleaned\\TestSetCleaned.csv\n",
    "* outputs\\datasets\\cleaned\\TrainSetCleaned.csv\n",
    "## Outputs\n",
    "* TrainSet and TestSet\n",
    "* Data cleaning and feature engineer pipeline \n",
    "* Modeling pipeline\n",
    "* Feature importance analysis\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages\n",
    "\n",
    "* Import packages using the 'import' statement followed by the name of the package. For example, 'import pandas' which is commonly used for data manipulation and analysis. This is  followed by and alias of your choice, preferably as pd although it is arbitrary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load Data\n",
    "### Change working directory\n",
    "We need to change the working directory from its current folder to its parent folder\n",
    "\n",
    "* We access the current directory with os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\issam\\\\Housing-market-analysis.1\\\\jupyter_notebooks'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to make the parent of the current directory the new current directory.\n",
    "\n",
    "    * os.path.dirname() gets the parent directory\n",
    "    * os.chir() defines the new current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.dirname(current_dir))\n",
    "# New current directory set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm the new current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\issam\\\\Housing-market-analysis.1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformations \n",
    "* Create engineered variables and integrate transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Gd\n",
      "1    Gd\n",
      "2    Fa\n",
      "3    TA\n",
      "4    TA\n",
      "5    Ex\n",
      "6    Gd\n",
      "7    Gd\n",
      "8    TA\n",
      "9    Gd\n",
      "Name: KitchenQual, dtype: object\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "   1stFlrSF  2ndFlrSF  BedroomAbvGr  BsmtExposure  BsmtFinSF1  BsmtFinType1  \\\n",
      "0      2158       0.0      4.000000           0.0         477           0.0   \n",
      "1      1614       0.0      3.000000           0.0          20           2.0   \n",
      "2       810     672.0      2.873045           3.0         156           1.0   \n",
      "3       894       0.0      3.000000           3.0         492           1.0   \n",
      "4       864       0.0      3.000000           3.0           0           6.0   \n",
      "5      1026     981.0      3.000000           0.0         765           2.0   \n",
      "6      1412       0.0      3.000000           2.0        1005           2.0   \n",
      "7       970     739.0      2.873045           3.0           0           6.0   \n",
      "8       894       0.0      2.000000           3.0           0           6.0   \n",
      "9      1085     649.0      3.000000           3.0         600           5.0   \n",
      "\n",
      "   BsmtUnfSF  GarageArea  GarageFinish  GarageYrBlt  ...  KitchenQual  \\\n",
      "0        725         576           3.0       1950.0  ...          2.0   \n",
      "1       1594         865           2.0       2005.0  ...          2.0   \n",
      "2        516         400           3.0       1934.0  ...          1.0   \n",
      "3        402         450           1.0       1968.0  ...          3.0   \n",
      "4        864         280           1.0       1972.0  ...          3.0   \n",
      "5        252         812           1.0       2008.0  ...          0.0   \n",
      "6        387         576           3.0       1988.0  ...          2.0   \n",
      "7        970         380           3.0       2004.0  ...          2.0   \n",
      "8        894         308           1.0       1962.0  ...          3.0   \n",
      "9        312         440           1.0       1962.0  ...          2.0   \n",
      "\n",
      "   LotArea  LotFrontage  MasVnrArea  OpenPorchSF  OverallCond  OverallQual  \\\n",
      "0    12615    84.000000         0.0           29            7            6   \n",
      "1    11210    86.000000       240.0           59            5            7   \n",
      "2    12155    70.243187         0.0            0            8            6   \n",
      "3     8724   109.000000         0.0            0            5            5   \n",
      "4     9353    71.000000         0.0            0            5            4   \n",
      "5    11003    85.000000       160.0           52            5           10   \n",
      "6    11457   130.000000         0.0            0            5            6   \n",
      "7     2522    24.000000        50.0           40            5            7   \n",
      "8     6600    60.000000         0.0            0            5            5   \n",
      "9     9786    77.000000         0.0            0            7            6   \n",
      "\n",
      "   TotalBsmtSF  YearBuilt  YearRemodAdd  \n",
      "0         1202       1950          2001  \n",
      "1         1614       2005          2006  \n",
      "2          672       1925          1950  \n",
      "3          894       1968          1968  \n",
      "4          864       1970          1970  \n",
      "5         1017       2008          2008  \n",
      "6         1392       1988          1988  \n",
      "7          970       2004          2004  \n",
      "8          894       1962          1962  \n",
      "9          912       1962          1981  \n",
      "\n",
      "[10 rows x 21 columns]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected a 2-dimensional container but got <class 'pandas.core.series.Series'> instead. Pass a DataFrame containing a single row (i.e. single sample) or a single column (i.e. single feature) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 54\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mpower(x, power)\n\u001b[0;32m     53\u001b[0m log_transformer \u001b[38;5;241m=\u001b[39m FunctionTransformer(log10_transform, validate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 54\u001b[0m X_train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGrLivArea\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mlog_transformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mGrLivArea\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m power_transformer \u001b[38;5;241m=\u001b[39m FunctionTransformer(power_transform, kw_args\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpower\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0.5\u001b[39m}, validate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     57\u001b[0m X_train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOverallQual\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m power_transformer\u001b[38;5;241m.\u001b[39mtransform(X_train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOverallQual\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\issam\\Housing-market-analysis.1\\.venv\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:295\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    294\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 295\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    297\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    298\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    299\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    300\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    301\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\issam\\Housing-market-analysis.1\\.venv\\Lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py:266\u001b[0m, in \u001b[0;36mFunctionTransformer.transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    253\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Transform X using the forward function.\u001b[39;00m\n\u001b[0;32m    254\u001b[0m \n\u001b[0;32m    255\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;124;03m        Transformed input.\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 266\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    267\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform(X, func\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc, kw_args\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkw_args)\n\u001b[0;32m    268\u001b[0m     output_config \u001b[38;5;241m=\u001b[39m _get_output_config(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransform\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdense\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\issam\\Housing-market-analysis.1\\.venv\\Lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py:190\u001b[0m, in \u001b[0;36mFunctionTransformer._check_input\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_input\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39m, reset):\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalidate:\n\u001b[1;32m--> 190\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    191\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m reset:\n\u001b[0;32m    192\u001b[0m         \u001b[38;5;66;03m# Set feature_names_in_ and n_features_in_ even if validate=False\u001b[39;00m\n\u001b[0;32m    193\u001b[0m         \u001b[38;5;66;03m# We run this only when reset==True to store the attributes but not\u001b[39;00m\n\u001b[0;32m    194\u001b[0m         \u001b[38;5;66;03m# validate them, because validate=False\u001b[39;00m\n\u001b[0;32m    195\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_n_features(X, reset\u001b[38;5;241m=\u001b[39mreset)\n",
      "File \u001b[1;32mc:\\Users\\issam\\Housing-market-analysis.1\\.venv\\Lib\\site-packages\\sklearn\\base.py:633\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    631\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 633\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    634\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[0;32m    635\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[1;32mc:\\Users\\issam\\Housing-market-analysis.1\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1035\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1028\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1029\u001b[0m             msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1030\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124marray=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marray\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1031\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1032\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1033\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif it contains a single sample.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1034\u001b[0m             )\n\u001b[1;32m-> 1035\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1037\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype_numeric \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(array\u001b[38;5;241m.\u001b[39mdtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkind\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSV\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1038\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1039\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1040\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1041\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Expected a 2-dimensional container but got <class 'pandas.core.series.Series'> instead. Pass a DataFrame containing a single row (i.e. single sample) or a single column (i.e. single feature) instead."
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, FunctionTransformer, PowerTransformer\n",
    "\n",
    "\n",
    "# Load the cleaned dataset \n",
    "# # The dataset is already cleaned and ready for transformation \n",
    "train_data = pd.read_csv('outputs\\datasets\\cleaned\\TrainSetCleaned.csv') \n",
    "\n",
    "test_data = pd.read_csv('outputs\\datasets\\cleaned\\TestSetCleaned.csv') \n",
    "\n",
    "# Separate the features and target variable in the training set \n",
    "X_train = train_data.drop('SalePrice', axis=1) \n",
    "\n",
    "y_train = train_data['SalePrice'] \n",
    "# Separate the features and target variable in the test set \n",
    "X_test = test_data.drop('SalePrice', axis=1) \n",
    "\n",
    "y_test = test_data['SalePrice'] \n",
    "# Define preprocessing steps for numerical and categorical variables \n",
    "numerical_features = X_train.columns[X_train.dtypes!='object'].to_list()\n",
    "# 1 - create two encoders for categorical variables\n",
    "# Encoder for KitchenQual\n",
    "category_orders = ['Po','Fa','TA','Gd','Ex']\n",
    "categorical_features = X_train.select_dtypes(include=['object', 'category']).columns.to_list()\n",
    "# kitchen_qual_encoder = OrdinalEncoder(categories=category_orders)\n",
    "# categorical_features.remove('KitchenQual')\n",
    "\n",
    "# Create encoder for other categorical variables\n",
    "encoder = OrdinalEncoder()\n",
    "\n",
    "# 2 - fit_transform into X_train\n",
    "print(X_train['KitchenQual'].head(10))\n",
    "print(type(X_train))\n",
    "\n",
    "# X_train['KitchenQualEncoded'] = kitchen_qual_encoder.fit_transform(X_train['KitchenQual'])\n",
    "# print(X_train['KitchenQualEncoded', 'KitchenQual'].head(10))\n",
    "X_train[categorical_features] = encoder.fit_transform(X_train[categorical_features])\n",
    "\n",
    "# 3 - transform into X_test \n",
    "X_test[categorical_features] = encoder.transform(X_test[categorical_features])\n",
    "\n",
    "X_train = pd.DataFrame(X_train)\n",
    "print(type(X_train))\n",
    "# print(X_train['categorical_variables'].head(10))\n",
    "print(X_train.head(10))\n",
    "\n",
    "# Create required tranformations for numerical variables\n",
    "def log10_transform(x):\n",
    "    return np.log10(x)\n",
    "\n",
    "def power_transform(x, power=0.5):\n",
    "    return np.power(x, power)\n",
    "\n",
    "log_transformer = FunctionTransformer(log10_transform, validate=True)\n",
    "X_train['GrLivArea'] = log_transformer.transform(X_train['GrLivArea'])\n",
    "\n",
    "power_transformer = FunctionTransformer(power_transform, kw_args={'power': 0.5}, validate=True)\n",
    "X_train['OverallQual'] = power_transformer.transform(X_train['OverallQual'])\n",
    "\n",
    "yeo_johnson_transformer = PowerTransformer(method='yeo_johnson')\n",
    "# X_train['GarageArea'] = yeo_johnson.fit_transform(X_train['GarageArea'])\n",
    "\n",
    "remainer_numerical_features = numerical_features.remove('GrLivArea').remove('OverallQual').remove('GarageArea')\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers = [ \n",
    "        ('yeo_johnson', yeo_johnson_transformer, ['GarageArea']),\n",
    "        ('passthrough', 'passthrough', remainer_numerical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 1. Create a transformer\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 2. Fit-Transform into X_train\n",
    "X_train[numerical_features] = scaler.fit_transform(X_train[numerical_features])\n",
    "\n",
    "# 3. Transform into X_test\n",
    "X_test[numerical_features] = scaler.transform(X_test[numerical_features])\n",
    "\n",
    "df_numerical_features = X_train.copy()\n",
    "df_numerical_features.head()\n",
    "\n",
    "from feature_engine.selection import SmartCorrelatedSelection\n",
    "corr_sel = SmartCorrelatedSelection(variables=None, method=\"spearman\", threshold=0.6, selection_method=\"variance\")\n",
    "\n",
    "corr_sel.fit_transform(df_numerical_features)\n",
    "corr_sel.correlated_feature_sets_\n",
    "\n",
    "corr_sel.features_to_drop_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: ML Pipeline with all data\n",
    "### ML pipeline for Data Cleaning and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#############################################################################################\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from feature_engine.selection import SmartCorrelatedSelection\n",
    "\n",
    "\n",
    "def PipelineDataCleaningAndFeatureEngineering():\n",
    "    # Converts Objects into Ints\n",
    "''' df['BsmtExposure'] = df['BsmtExposure'].astype('category').cat.codes\n",
    "    df['BsmtFinType1'] = df['BsmtFinType1'].astype('category').cat.codes\n",
    "    df['GarageFinish'] = df['GarageFinish'].astype('category').cat.codes\n",
    "    df['KitchenQual'] = df['KitchenQual'].astype('category').cat.codes\n",
    "'''\n",
    "    \n",
    "    # Combine preprocessing with feature selection\n",
    "    pipeline_base = Pipeline([\n",
    "        (\"feature_selection\", SelectFromModel(RandomForestRegressor())),\n",
    "        (\"SmartCorrelatedSelection\", SmartCorrelatedSelection(variables=None,\n",
    "                                                              method=\"pearson\", threshold=0.9, selection_method=\"variance\")),\n",
    "    ])\n",
    "\n",
    "    return pipeline_base\n",
    "\n",
    "PipelineDataCleaningAndFeatureEngineering()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All categorical features have been converted into numerical features\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML Pipeline for Modelling and Hyperparameter Optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feat Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Feat Selection\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# ML algorithms\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "# from xgboost import XGBRegressor\n",
    "\n",
    "\n",
    "def PipelineReg(model):\n",
    "    pipeline_base = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"feat_selection\", SelectFromModel(model)),\n",
    "        (\"model\", model),\n",
    "    ])\n",
    "\n",
    "    return pipeline_base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Class for Hyperparameter Optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "class HyperparameterOptimizationSearch:\n",
    "\n",
    "    def __init__(self, models, params):\n",
    "        self.models = models\n",
    "        self.params = params\n",
    "        self.keys = models.keys()\n",
    "        self.grid_searches = {}\n",
    "\n",
    "    def fit(self, X, y, cv, n_jobs, verbose=1, scoring=None, refit=False):\n",
    "        for key in self.keys:\n",
    "            print(f\"\\nRunning GridSearchCV for {key} \\n\")\n",
    "\n",
    "            model = PipelineReg(self.models[key])\n",
    "            params = self.params[key]\n",
    "            gs = GridSearchCV(model, params, cv=cv, n_jobs=n_jobs,\n",
    "                              verbose=verbose, scoring=scoring, )\n",
    "            gs.fit(X, y)\n",
    "            self.grid_searches[key] = gs\n",
    "\n",
    "    def score_summary(self, sort_by='mean_score'):\n",
    "        def row(key, scores, params):\n",
    "            d = {\n",
    "                'estimator': key,\n",
    "                'min_score': min(scores),\n",
    "                'max_score': max(scores),\n",
    "                'mean_score': np.mean(scores),\n",
    "                'std_score': np.std(scores),\n",
    "            }\n",
    "            return pd.Series({**params, **d})\n",
    "\n",
    "        rows = []\n",
    "        for k in self.grid_searches:\n",
    "            params = self.grid_searches[k].cv_results_['params']\n",
    "            scores = []\n",
    "            for i in range(self.grid_searches[k].cv):\n",
    "                key = \"split{}_test_score\".format(i)\n",
    "                r = self.grid_searches[k].cv_results_[key]\n",
    "                scores.append(r.reshape(len(params), 1))\n",
    "\n",
    "            all_scores = np.hstack(scores)\n",
    "            for p, s in zip(params, all_scores):\n",
    "                rows.append((row(k, s, p)))\n",
    "\n",
    "        df = pd.concat(rows, axis=1).T.sort_values([sort_by], ascending=False)\n",
    "        columns = ['estimator', 'min_score',\n",
    "                   'mean_score', 'max_score', 'std_score']\n",
    "        columns = columns + [c for c in df.columns if c not in columns]\n",
    "        return df[columns], self.grid_searches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Train and Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.drop(['SalePrice'], axis=1),\n",
    "    df['SalePrice'],\n",
    "    test_size=0.2,\n",
    "    random_state=101,\n",
    ")\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_data_cleaning_feat_eng = PipelineDataCleaningAndFeatureEngineering()\n",
    "X_train_original = X_train\n",
    "print(X_train_original.shape)\n",
    "X_train = pipeline_data_cleaning_feat_eng.fit_transform(X_train, y_train) \n",
    "X_test = pipeline_data_cleaning_feat_eng.transform(X_test)\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle Target Imbalance "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check Train Set Target distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set a random seed\n",
    "np.random.seed(101)\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "#subsampled_counts = y_train.value_counts().sample(n=20)  # Adjust the sample size as needed\n",
    "subsampled_counts = y_train.value_counts().sample(n=min(20, y_train.nunique()))\n",
    "plt.figure(figsize=(10, 6))  # Adjust figure size as needed\n",
    "ax = subsampled_counts.plot(kind='bar', title='Train Set Target Distribution')\n",
    "ax.tick_params(axis='x', rotation=45)# Rotate x-axis labels\n",
    "print(len(y_train))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use algorithms that handle class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import NearMiss\n",
    "\n",
    "# Define the NearMiss undersampler\n",
    "undersampler = NearMiss(version=1, n_neighbors=1)\n",
    "\n",
    "# Apply NearMiss undersampling to the dataset\n",
    "X_resampled, y_resampled = undersampler.fit_resample(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check Train Set Target distribution after resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Set a random seed\n",
    "np.random.seed(102)\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "#subsampled_counts = y_train.value_counts().sample(n=20)  # Adjust the sample size as needed\n",
    "subsampled_counts = y_train.value_counts().sample(n=min(20, y_train.nunique()))\n",
    "plt.figure(figsize=(10, 6))  # Adjust figure size as needed\n",
    "ax = subsampled_counts.plot(kind='bar', title='Train Set Target Distribution')\n",
    "ax.tick_params(axis='x', rotation=45)# Rotate x-axis labels\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search CV - Sklearn\n",
    "#### Use standard hyperparameters to find most suitable algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_search = {\n",
    "    \"DecisionTreeRegressor\": DecisionTreeRegressor(random_state=101),\n",
    "    \"RandomForestRegressor\": RandomForestRegressor(random_state=101),\n",
    "    \"ExtraTreesRegressor\": ExtraTreesRegressor(random_state=101),\n",
    "    \"AdaBoostRegressor\": AdaBoostRegressor(random_state=101),# algorithm='SAMME'\n",
    "}\n",
    "\n",
    "params_search = {\n",
    "    \"DecisionTreeRegressor\": {},\n",
    "    \"RandomForestRegressor\": {},\n",
    "    \"ExtraTreesRegressor\": {},\n",
    "    \"AdaBoostRegressor\": {},\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train.unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick GridSearch CV - Binary Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, r2_score\n",
    "\n",
    "search = HyperparameterOptimizationSearch(models=models_search, params=params_search)\n",
    "search.fit(X_train, y_train,\n",
    "           scoring =  make_scorer(r2_score),\n",
    "           n_jobs=-1, cv=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_summary, grid_search_pipelines = search.score_summary(sort_by='mean_score')\n",
    "grid_search_summary "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do an extensive search on the most suitable algorithm to find the best hyperparameter configuration.\n",
    "Define model and parameters, for Extensive Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "models_search = {\n",
    "    \"RandomForestRegressor\": RandomForestRegressor(random_state=101),\n",
    "}\n",
    "\n",
    "# Documentation to help on hyperparameter list:\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html\n",
    "\n",
    "# We will not conduct an extensive search, since the focus\n",
    "# is on how to combine all knowledge in an applied project.\n",
    "# In a workplace project, you may spend more time in this step\n",
    "params_search = {\n",
    "    \"RandomForestRegressor\": {\n",
    "        'model__n_estimators': [100,150,200],\n",
    "        'model__max_depth': [None, 10, 20,],\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extensive GridSearch CV - Binary Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, make_scorer\n",
    "search = HyperparameterOptimizationSearch(models=models_search, params=params_search)\n",
    "search.fit(X_train, y_train, \n",
    "           scoring =  make_scorer(r2_score,),\n",
    "           n_jobs=-1, cv=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_summary, grid_search_pipelines = search.score_summary(sort_by='mean_score')\n",
    "grid_search_summary "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get best model name programmatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = grid_search_summary.iloc[0,0]\n",
    "best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters for best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_parameters = grid_search_pipelines[best_model].best_params_\n",
    "best_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the best clf pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_reg = grid_search_pipelines[best_model].best_estimator_\n",
    "print(pipeline_reg['feat_selection'].get_support())\n",
    "pipeline_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assess feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert X_train to a pandas DataFrame\n",
    "X_train_df = pd.DataFrame(X_train)\n",
    "\n",
    "# Now use the .tail() method\n",
    "X_train_df.tail()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* With the current model, we can assess with .features_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming X_train is your NumPy array ()\n",
    "#X_train_df = pd.DataFrame(X_train_original)\n",
    "print(X_train.shape)\n",
    "print(X_train_df.shape)\n",
    "\n",
    "# Now you can access the columns attribute \n",
    "columns = X_train_df.columns\n",
    "print(pipeline_reg)\n",
    "print(' next  ')\n",
    "print(columns)\n",
    "\n",
    "# Access feature importances from the feature selection step\n",
    "feat_selector = pipeline_reg.named_steps['feat_selection'].estimator_\n",
    "feat_selector_importances = feat_selector.feature_importances_\n",
    "\n",
    "print(\"feat selector:\",feat_selector)\n",
    "print(\"Feature importances from SelectFromModel step:\", feat_selector_importances)\n",
    "\n",
    "\n",
    "# create DataFrame to display feature importance\n",
    "df_feature_importance = (pd.DataFrame(data={\n",
    "    # 'Feature': columns[pipeline_reg['feat_selection'].get_support()],\n",
    "    'Feature': columns,\n",
    "    # 'Importance': pipeline_reg['model'].feature_importances_\n",
    "    'Importance':feat_selector_importances})\n",
    "    .sort_values(by='Importance', ascending=False))\n",
    "                                    \n",
    "\n",
    "# re-assign best_features order\n",
    "best_features = df_feature_importance['Feature'].to_list()\n",
    "\n",
    "# Most important features statement and plot\n",
    "print(f\"* These are the {len(best_features)} most important features in descending order. \"\n",
    "      f\"The model was trained on them: \\n{df_feature_importance['Feature'].to_list()}\")\n",
    "\n",
    "df_feature_importance.plot(kind='bar', x='Feature', y='Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Pipeline on Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "def reg_performance(X_train, y_train, X_test, y_test, pipeline):\n",
    "    print(\"#### Train Set #### \\n\")\n",
    "    y_train_pred = pipeline.predict(X_train)\n",
    "    print(\"Mean Squared Error (Train):\", mean_squared_error(y_train, y_train_pred))\n",
    "    print(\"R2 Score (Train):\", r2_score(y_train, y_train_pred))\n",
    "\n",
    "    print(\"\\n#### Test Set ####\\n\")\n",
    "    y_test_pred = pipeline.predict(X_test)\n",
    "    print(\"Mean Squared Error (Test):\", mean_squared_error(y_test, y_test_pred))\n",
    "    print(\"R2 Score (Test):\", r2_score(y_test, y_test_pred))\n",
    "\n",
    "    # Plot Actual vs. Predicted for training data\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.scatter(y_train, y_train_pred, alpha=0.5)\n",
    "    plt.plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], '--', color='red')\n",
    "    plt.xlabel('Actual')\n",
    "    plt.ylabel('Predicted')\n",
    "    plt.title('Actual vs. Predicted (Training)')\n",
    "    \n",
    "    # Plot Actual vs. Predicted for test data\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.scatter(y_test, y_test_pred, alpha=0.5)\n",
    "    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], '--', color='red')\n",
    "    plt.xlabel('Actual')\n",
    "    plt.ylabel('Predicted')\n",
    "    plt.title('Actual vs. Predicted (Test)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Suppress undefined metric warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation: We cross check with metrics defined at ML business case\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_performance(X_train=X_train, y_train=y_train,\n",
    "                 X_test=X_test, y_test=y_test,\n",
    "                 pipeline=pipeline_reg,\n",
    "                )\n",
    "\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Refit pipeline with best features\n",
    "### Refit ML Pipeline and Resampling\n",
    "In theory, a pipeline fitted **using only the most important features** should give the same result as the one fitted with **all variables and feature selection**.\n",
    "\n",
    "### Rewrite ML pipeline for Data Cleaning and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New Pipeline for DataCleaning And FeatureEngineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_engine.encoding import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "\n",
    "def PipelineDataCleaningAndFeatureEngineering():\n",
    "    pipeline_base = Pipeline([\n",
    "    \n",
    "        # Scale numerical features\n",
    "        (\"Scaler\", StandardScaler()),  \n",
    "        (\"feature_selection\", SelectFromModel(RandomForestRegressor())),\n",
    "    ])\n",
    "\n",
    "    return pipeline_base\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rewrite ML Pipeline for Modelling\n",
    "Function for Pipeline optmisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline Optimization: Model\n",
    "def PipelineReg(model):\n",
    "    pipeline_base = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"model\", model),\n",
    "    ])\n",
    "\n",
    "    return pipeline_base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Train Test Set, considering only with best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into features (X) and target variable (y)\n",
    "X = df.drop(['SalePrice'], axis=1)\n",
    "y = df['SalePrice']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split\n",
    "X_train, X_test, y_train, y_test,  = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=101,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle Target Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_data_cleaning_feat_eng = PipelineDataCleaningAndFeatureEngineering()\n",
    "\n",
    "X_train = pipeline_data_cleaning_feat_eng.fit_transform(X_train, y_train)\n",
    "X_test = pipeline_data_cleaning_feat_eng.transform(X_test)\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check Train Set Target distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set figure size\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "np.random.seed(101)\n",
    "\n",
    "# Plot bar chart\n",
    "counts = y_train.value_counts()\n",
    "# Subsample the counts\n",
    "subsampled_counts = counts.sample(n=min(20, len(counts)))  \n",
    "\n",
    "subsampled_counts.plot(kind='bar', title='Train Set Target Distribution')\n",
    "\n",
    "# Set title and labels\n",
    "plt.title('Train Set Target Distribution')\n",
    "plt.xlabel('Target Value')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "# Rotate x-axis labels\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Adjust layout to prevent overlapping\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use NearMiss to balance Train Set target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import NearMiss\n",
    "\n",
    "# Define the NearMiss undersampler\n",
    "undersampler = NearMiss(version=1, n_neighbors=1)\n",
    "\n",
    "# Apply NearMiss undersampling to the dataset\n",
    "X_resampled, y_resampled = undersampler.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check Train Set Target distribution after NearMiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set figure size\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "np.random.seed(101)\n",
    "\n",
    "# Plot bar chart\n",
    "counts = y_train.value_counts()\n",
    "# Subsample the counts\n",
    "subsampled_counts = counts.sample(n=min(20, len(counts)))  \n",
    "\n",
    "subsampled_counts.plot(kind='bar', title='Train Set Target Distribution')\n",
    "\n",
    "# Set title and labels\n",
    "plt.title('Train Set Target Distribution')\n",
    "plt.xlabel('Target Value')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "# Rotate x-axis labels\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Adjust layout to prevent overlapping\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search CV: Sklearn\n",
    "Using the most suitable model from the last section and its best hyperparameter configuration.\n",
    "\n",
    "We are using the same model from the last GridCV search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_search  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the best parameters from the last GridCV search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to type in manually since the hyperparameter values have to be a list. The previous dictionary is not in this format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_search = {\n",
    "    'RandomForestRegressor': {\n",
    "        'model__n_estimators': [100, 300, 500],\n",
    "        'model__max_depth': [None, 10, 30],\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GridSearch CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.metrics import make_scorer, r2_score\n",
    "\n",
    "quick_search = HyperparameterOptimizationSearch(\n",
    "    models=models_search, params=params_search)\n",
    "quick_search.fit(X_train, y_train,\n",
    "                 scoring=make_scorer(r2_score, ),\n",
    "                 n_jobs=-1, cv=3)\n",
    "\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_summary, grid_search_pipelines = quick_search.score_summary(sort_by='mean_score')\n",
    "grid_search_summary "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the best clf pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_model = grid_search_summary.iloc[0, 0]\n",
    "pipeline_reg = grid_search_pipelines[best_model].best_estimator_\n",
    "pipeline_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assess feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"best_features:\", best_features)\n",
    "print(\"feature_importances:\", pipeline_reg['model'].feature_importances_)\n",
    "print(\"Length of best_features:\", len(best_features))\n",
    "print(\"Length of feature_importances:\", len(pipeline_reg['model'].feature_importances_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create DataFrame to display feature importance\n",
    "df_feature_importance = (pd.DataFrame(data={\n",
    "    'Feature': columns.tolist(),\n",
    "    'Importance': pipeline_reg['model'].feature_importances_})\n",
    "    .sort_values(by='Importance', ascending=False)\n",
    ")\n",
    "\n",
    "\n",
    "# Most important features statement and plot\n",
    "print(f\"* These are the {len(best_features)} most important features in descending order. \"\n",
    "      f\"The model was trained on them: \\n{df_feature_importance['Feature'].to_list()}\")\n",
    "\n",
    "df_feature_importance.plot(kind='bar', x='Feature', y='Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Pipeline on Train and Test Sets\n",
    "Evaluation: We cross-check with metrics defined in the ML business case.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_performance(X_train=X_train, y_train=y_train,\n",
    "                X_test=X_test, y_test=y_test,\n",
    "                pipeline=pipeline_reg,\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Push files to Repo\n",
    "We will generate the following files\n",
    "\n",
    "* Train set\n",
    "* Test set\n",
    "* Data cleaning and Feature Engineering pipeline\n",
    "* Modeling pipeline\n",
    "* features importance plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "version = 'v1'\n",
    "file_path = f'outputs/ml_pipeline/predict_saleprice/{version}'\n",
    "\n",
    "try:\n",
    "    os.makedirs(name=file_path)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "# X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm not sure when or how X_train became a numpy array. but I used the pd.DataFrame() method to convert it back into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert X_train to a DataFrame\n",
    "X_train_df = pd.DataFrame(X_train)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "X_train_df.to_csv(f\"{file_path}/X_train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df.to_csv(f\"{file_path}/X_train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.to_csv(f\"{file_path}/y_train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Set\n",
    "* note that the variables are transformed already in X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert X_test to a DataFrame\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "\n",
    "# Now you can use DataFrame methods like head()\n",
    "X_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test_df.shape)\n",
    "X_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_df.to_csv(f\"{file_path}/X_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.to_csv(f\"{file_path}/y_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Pipelines: Data Cleaning and Feat Eng pipeline and Modelling Pipeline\n",
    "We will save 2 pipelines:\n",
    "\n",
    "* Both should be used in conjunction to predict Live Data.\n",
    "* To predict on Train Set, Test Set we use only pipeline_reg, since the data is already processed.\n",
    "Pipeline responsible for Data Cleaning and Feature Engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_data_cleaning_feat_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(value=pipeline_data_cleaning_feat_eng ,\n",
    "            filename=f\"{file_path}/clf_pipeline_model.pkl\")\n",
    "joblib.dump(value=pipeline_reg ,\n",
    "            filename=f\"{file_path}/clf_pipeline_predict.pkl\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature_importance.plot(kind='bar',x='Feature',y='Importance', figsize=(3, 6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature_importance.plot(kind='bar', x='Feature', y='Importance', figsize=(3,6))\n",
    "plt.savefig(f'{file_path}/features_importance.png', bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
