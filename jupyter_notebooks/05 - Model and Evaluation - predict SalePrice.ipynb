{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression\n",
    "## Objectives\n",
    "* Fit and evaluate a regression model for predicting property sale prices using our training and testing datasets.\n",
    "## Inputs\n",
    "* outputs\\datasets\\cleaned\\TestSetCleaned.csv\n",
    "* outputs\\datasets\\cleaned\\TrainSetCleaned.csv\n",
    "## Outputs\n",
    "* TrainSet and TestSet\n",
    "* Data cleaning and feature engineer pipeline \n",
    "* Modeling pipeline\n",
    "* Feature importance analysis\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages\n",
    "\n",
    "* Import packages using the 'import' statement followed by the name of the package. For example, 'import pandas' which is commonly used for data manipulation and analysis. This is  followed by and alias of your choice, preferably as pd although it is arbitrary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load Data\n",
    "### Change working directory\n",
    "We need to change the working directory from its current folder to its parent folder\n",
    "\n",
    "* We access the current directory with os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\issam\\\\Housing-market-analysis.1\\\\jupyter_notebooks'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to make the parent of the current directory the new current directory.\n",
    "\n",
    "    * os.path.dirname() gets the parent directory\n",
    "    * os.chir() defines the new current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.dirname(current_dir))\n",
    "# New current directory set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm the new current directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\issam\\\\Housing-market-analysis.1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_dir = os.getcwd()\n",
    "current_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1160, 22)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>2ndFlrSF</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>BsmtExposure</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinType1</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>GarageFinish</th>\n",
       "      <th>GarageYrBlt</th>\n",
       "      <th>...</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2158</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>Av</td>\n",
       "      <td>477</td>\n",
       "      <td>ALQ</td>\n",
       "      <td>725</td>\n",
       "      <td>576</td>\n",
       "      <td>Unf</td>\n",
       "      <td>1950.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12615</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1202</td>\n",
       "      <td>1950</td>\n",
       "      <td>2001</td>\n",
       "      <td>243000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1614</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>Av</td>\n",
       "      <td>20</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>1594</td>\n",
       "      <td>865</td>\n",
       "      <td>RFn</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11210</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>240.0</td>\n",
       "      <td>59</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1614</td>\n",
       "      <td>2005</td>\n",
       "      <td>2006</td>\n",
       "      <td>221500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>810</td>\n",
       "      <td>672.0</td>\n",
       "      <td>2.873045</td>\n",
       "      <td>No</td>\n",
       "      <td>156</td>\n",
       "      <td>BLQ</td>\n",
       "      <td>516</td>\n",
       "      <td>400</td>\n",
       "      <td>Unf</td>\n",
       "      <td>1934.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12155</td>\n",
       "      <td>70.243187</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>672</td>\n",
       "      <td>1925</td>\n",
       "      <td>1950</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>894</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>No</td>\n",
       "      <td>492</td>\n",
       "      <td>BLQ</td>\n",
       "      <td>402</td>\n",
       "      <td>450</td>\n",
       "      <td>Non</td>\n",
       "      <td>1968.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8724</td>\n",
       "      <td>109.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>894</td>\n",
       "      <td>1968</td>\n",
       "      <td>1968</td>\n",
       "      <td>129000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>864</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>Unf</td>\n",
       "      <td>864</td>\n",
       "      <td>280</td>\n",
       "      <td>Non</td>\n",
       "      <td>1972.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9353</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>864</td>\n",
       "      <td>1970</td>\n",
       "      <td>1970</td>\n",
       "      <td>116050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   1stFlrSF  2ndFlrSF  BedroomAbvGr BsmtExposure  BsmtFinSF1 BsmtFinType1  \\\n",
       "0      2158       0.0      4.000000           Av         477          ALQ   \n",
       "1      1614       0.0      3.000000           Av          20          GLQ   \n",
       "2       810     672.0      2.873045           No         156          BLQ   \n",
       "3       894       0.0      3.000000           No         492          BLQ   \n",
       "4       864       0.0      3.000000           No           0          Unf   \n",
       "\n",
       "   BsmtUnfSF  GarageArea GarageFinish  GarageYrBlt  ...  LotArea LotFrontage  \\\n",
       "0        725         576          Unf       1950.0  ...    12615   84.000000   \n",
       "1       1594         865          RFn       2005.0  ...    11210   86.000000   \n",
       "2        516         400          Unf       1934.0  ...    12155   70.243187   \n",
       "3        402         450          Non       1968.0  ...     8724  109.000000   \n",
       "4        864         280          Non       1972.0  ...     9353   71.000000   \n",
       "\n",
       "   MasVnrArea  OpenPorchSF  OverallCond  OverallQual  TotalBsmtSF  YearBuilt  \\\n",
       "0         0.0           29            7            6         1202       1950   \n",
       "1       240.0           59            5            7         1614       2005   \n",
       "2         0.0            0            8            6          672       1925   \n",
       "3         0.0            0            5            5          894       1968   \n",
       "4         0.0            0            5            4          864       1970   \n",
       "\n",
       "   YearRemodAdd  SalePrice  \n",
       "0          2001     243000  \n",
       "1          2006     221500  \n",
       "2          1950     140000  \n",
       "3          1968     129000  \n",
       "4          1970     116050  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df = (pd.read_csv(\"outputs\\datasets\\cleaned\\TrainSetCleaned.csv\")\n",
    ")\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformations \n",
    "* Create engineered variables and integrate transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4127359540.py, line 62)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[6], line 62\u001b[1;36m\u001b[0m\n\u001b[1;33m    categorical_transformer =\u001b[0m\n\u001b[1;37m                              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from feature_engine import transformation as vt\n",
    "from feature_engine.outliers import Winsorizer\n",
    "from feature_engine.encoding import OrdinalEncoder as FE_OrdinalEncoder\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image, display\n",
    "sns.set(style=\"whitegrid\")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer \n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, FunctionTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Load the cleaned dataset \n",
    "# The dataset is already cleaned and ready for transformation\n",
    "train_data = pd.read_csv('outputs\\datasets\\cleaned\\TrainSetCleaned.csv') \n",
    "# Assuming you have the train set in a file called train_data.csv\n",
    "test_data = pd.read_csv('outputs\\datasets\\cleaned\\TestSetCleaned.csv') \n",
    "# Assuming you have the test set in a file called test_data.csv\n",
    "# Separate the features and target variable in the training set\n",
    "X_train = train_data.drop('SalePrice', axis=1) \n",
    "# Assuming 'SalePrice' is the target variable\n",
    "y_train = train_data['SalePrice'] \n",
    "# Separate the features and target variable in the test set\n",
    "X_test = test_data.drop('SalePrice', axis=1) \n",
    "# Assuming 'SalePrice' is the target variable\n",
    "y_test = test_data['SalePrice'] \n",
    "# Define preprocessing steps for numerical and categorical variables\n",
    "numeric_features = X_train.columns[X_train.dtypes!='object'].to_list()\n",
    "transformed_num_features = ['GarageArea', 'GrLivArea']\n",
    "no_transform_num_features = [item for item in numeric_features if item not in transformed_num_features]\n",
    "# Replace with actual numerical feature names\n",
    "# Use FunctionTransformer to apply different transformations to different features\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('power_tranform',\n",
    "ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('log_GarageArea', FunctionTransformer(np.log1p, validate=True), ['GarageArea']),\n",
    "        ('log_GrLivArea', FunctionTransformer(np.log1p, validate=True), ['GrLivArea']), \n",
    "        ('no_transform', 'passthrough', no_transform_num_features) \n",
    "    ]))])\n",
    "# For the categorical features, use OrdinalEncoder with encoding based on the mean of SalePrice\n",
    "categorical_features = X_train.select_dtypes(include=['object']).columns.to_list()\n",
    "# ['KitchenQual'] \n",
    "arbitrary_encoder_features = [feature for feature in categorical_features if feature != 'KitchenQual']\n",
    "print(arbitrary_encoder_features)\n",
    "# Create a new feature based on the mean SalePrice per category for KitchenQual\n",
    "mean_sale_price_per_kitchen_qual = train_data.groupby('KitchenQual')['SalePrice'].mean().sort_values().index.to_list()\n",
    "\n",
    "\n",
    "# Define a custom encoder using the mean of SalePrice for encoding KitchenQual\n",
    "encoder_kitchen_qual = FE_OrdinalEncoder(encoding_method='ordered', variables=['KitchenQual'])\n",
    "# Define an arbitrary encoder for other categorical features\n",
    "encoder_others = FE_OrdinalEncoder(encoding_method='arbitrary', variables=arbitrary_encoder_features)\n",
    "\n",
    "categorical_transformer = \n",
    "Pipeline(steps=[\n",
    "    ('ordinal_encoding_kitchen_qual', encoder_kitchen_qual),\n",
    "    ('ordinal_encoding_others', encoder_others) \n",
    "    # Replace with actual categorical feature names except KitchenQual\n",
    "])\n",
    "\n",
    "# Combine preprocessing steps for numerical and categorical variables using ColumnTransformer\n",
    "preprocessor = ColumnTransformer( \n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features), \n",
    "        ('cat', categorical_transformer, categorical_features) \n",
    "    ]\n",
    ")\n",
    "# Create the full pipeline including preprocessing, PCA, and model training \n",
    "\n",
    "pipeline = Pipeline(steps=[ \n",
    "    ('preprocessor', preprocessor),# Apply preprocessing steps \n",
    "    ('pca', PCA(n_components=10)),# Apply PCA for dimensionality reduction \n",
    "    ('classifier', LogisticRegression()) # Train logistic regression model \n",
    "]) \n",
    "\n",
    "# Fit the pipeline on training data and make predictions \n",
    "pipeline.fit(X_train, y_train) \n",
    "# Fit the pipeline on training data \n",
    "# and make predictions using the fitted pipeline\n",
    "y_pred = pipeline.predict(X_test) \n",
    "# Evaluate the model\n",
    "print(f\"Accuracy: {pipeline.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: ML Pipeline with all data\n",
    "### ML pipeline for Data Cleaning and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1 - create two encoders for categorical variables\n",
    "# Encoder for KitchenQual\n",
    "kitchen_qual_encoder = OrdinalEncoder(dict(KitchenQual=['Po','Fa','TA','Gd','Ex']), encoding_method='arbitrary',\n",
    "variables = ['KitchenQual'])\n",
    "categorical_variables.remove('KitchenQual')\n",
    "\n",
    "# Create encoder for other categorical variables\n",
    "encoder = OrdinalEncoder(encoding_method='arbitrary', variables = categorical_variables)\n",
    "\n",
    "# 2 - fit_transform into TrainSet\n",
    "print(TrainSet.head(10))\n",
    "TrainSet['KitchenQualencoded'] = kitchen_qual_encoder.fit_transform(TrainSet['KitchenQual'])\n",
    "TrainSet = encoder.fit_transform(TrainSet)\n",
    "# print(TrainSet['categorical_variables'].head(10))\n",
    "print(TrainSet.head(10))\n",
    "\n",
    "# 3 - transform into TestSet \n",
    "TestSet['KitchenQual'] = kitchen_qual_encoder.transform(TestSet['KitchenQual'])\n",
    "\n",
    "# 1. Create a transformer\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 2. Fit-Transform into TrainSet\n",
    "TrainSet[numerical_variables] = scaler.fit_transform(TrainSet[numerical_variables])\n",
    "\n",
    "# 3. Transform into TestSet\n",
    "TestSet[numerical_variables] = scaler.transform(TestSet[numerical_variables])\n",
    "\n",
    "df_numerical_variables = TrainSet.copy()\n",
    "df_numerical_variables.head()\n",
    "\n",
    "from feature_engine.selection import SmartCorrelatedSelection\n",
    "corr_sel = SmartCorrelatedSelection(variables=None, method=\"spearman\", threshold=0.6, selection_method=\"variance\")\n",
    "\n",
    "corr_sel.fit_transform(df_numerical_variables)\n",
    "corr_sel.correlated_feature_sets_\n",
    "\n",
    "corr_sel.features_to_drop_\n",
    "\n",
    "#############################################################################################\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from feature_engine.selection import SmartCorrelatedSelection\n",
    "\n",
    "\n",
    "def PipelineDataCleaningAndFeatureEngineering():\n",
    "    # Converts Objects into Ints\n",
    "    df['BsmtExposure'] = df['BsmtExposure'].astype('category').cat.codes\n",
    "    df['BsmtFinType1'] = df['BsmtFinType1'].astype('category').cat.codes\n",
    "    df['GarageFinish'] = df['GarageFinish'].astype('category').cat.codes\n",
    "    df['KitchenQual'] = df['KitchenQual'].astype('category').cat.codes\n",
    "\n",
    "    \n",
    "    # Combine preprocessing with feature selection\n",
    "    pipeline_base = Pipeline([\n",
    "        (\"feature_selection\", SelectFromModel(RandomForestRegressor())),\n",
    "        (\"SmartCorrelatedSelection\", SmartCorrelatedSelection(variables=None,\n",
    "                                                              method=\"pearson\", threshold=0.9, selection_method=\"variance\")),\n",
    "    ])\n",
    "\n",
    "    return pipeline_base\n",
    "\n",
    "PipelineDataCleaningAndFeatureEngineering()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All categorical features have been converted into numerical features\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML Pipeline for Modelling and Hyperparameter Optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feat Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Feat Selection\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# ML algorithms\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "# from xgboost import XGBRegressor\n",
    "\n",
    "\n",
    "def PipelineReg(model):\n",
    "    pipeline_base = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"feat_selection\", SelectFromModel(model)),\n",
    "        (\"model\", model),\n",
    "    ])\n",
    "\n",
    "    return pipeline_base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Class for Hyperparameter Optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "class HyperparameterOptimizationSearch:\n",
    "\n",
    "    def __init__(self, models, params):\n",
    "        self.models = models\n",
    "        self.params = params\n",
    "        self.keys = models.keys()\n",
    "        self.grid_searches = {}\n",
    "\n",
    "    def fit(self, X, y, cv, n_jobs, verbose=1, scoring=None, refit=False):\n",
    "        for key in self.keys:\n",
    "            print(f\"\\nRunning GridSearchCV for {key} \\n\")\n",
    "\n",
    "            model = PipelineReg(self.models[key])\n",
    "            params = self.params[key]\n",
    "            gs = GridSearchCV(model, params, cv=cv, n_jobs=n_jobs,\n",
    "                              verbose=verbose, scoring=scoring, )\n",
    "            gs.fit(X, y)\n",
    "            self.grid_searches[key] = gs\n",
    "\n",
    "    def score_summary(self, sort_by='mean_score'):\n",
    "        def row(key, scores, params):\n",
    "            d = {\n",
    "                'estimator': key,\n",
    "                'min_score': min(scores),\n",
    "                'max_score': max(scores),\n",
    "                'mean_score': np.mean(scores),\n",
    "                'std_score': np.std(scores),\n",
    "            }\n",
    "            return pd.Series({**params, **d})\n",
    "\n",
    "        rows = []\n",
    "        for k in self.grid_searches:\n",
    "            params = self.grid_searches[k].cv_results_['params']\n",
    "            scores = []\n",
    "            for i in range(self.grid_searches[k].cv):\n",
    "                key = \"split{}_test_score\".format(i)\n",
    "                r = self.grid_searches[k].cv_results_[key]\n",
    "                scores.append(r.reshape(len(params), 1))\n",
    "\n",
    "            all_scores = np.hstack(scores)\n",
    "            for p, s in zip(params, all_scores):\n",
    "                rows.append((row(k, s, p)))\n",
    "\n",
    "        df = pd.concat(rows, axis=1).T.sort_values([sort_by], ascending=False)\n",
    "        columns = ['estimator', 'min_score',\n",
    "                   'mean_score', 'max_score', 'std_score']\n",
    "        columns = columns + [c for c in df.columns if c not in columns]\n",
    "        return df[columns], self.grid_searches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Train and Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.drop(['SalePrice'], axis=1),\n",
    "    df['SalePrice'],\n",
    "    test_size=0.2,\n",
    "    random_state=101,\n",
    ")\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_data_cleaning_feat_eng = PipelineDataCleaningAndFeatureEngineering()\n",
    "X_train_original = X_train\n",
    "print(X_train_original.shape)\n",
    "X_train = pipeline_data_cleaning_feat_eng.fit_transform(X_train, y_train) \n",
    "X_test = pipeline_data_cleaning_feat_eng.transform(X_test)\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle Target Imbalance "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check Train Set Target distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set a random seed\n",
    "np.random.seed(101)\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "#subsampled_counts = y_train.value_counts().sample(n=20)  # Adjust the sample size as needed\n",
    "subsampled_counts = y_train.value_counts().sample(n=min(20, y_train.nunique()))\n",
    "plt.figure(figsize=(10, 6))  # Adjust figure size as needed\n",
    "ax = subsampled_counts.plot(kind='bar', title='Train Set Target Distribution')\n",
    "ax.tick_params(axis='x', rotation=45)# Rotate x-axis labels\n",
    "print(len(y_train))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use algorithms that handle class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import NearMiss\n",
    "\n",
    "# Define the NearMiss undersampler\n",
    "undersampler = NearMiss(version=1, n_neighbors=1)\n",
    "\n",
    "# Apply NearMiss undersampling to the dataset\n",
    "X_resampled, y_resampled = undersampler.fit_resample(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check Train Set Target distribution after resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Set a random seed\n",
    "np.random.seed(102)\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "#subsampled_counts = y_train.value_counts().sample(n=20)  # Adjust the sample size as needed\n",
    "subsampled_counts = y_train.value_counts().sample(n=min(20, y_train.nunique()))\n",
    "plt.figure(figsize=(10, 6))  # Adjust figure size as needed\n",
    "ax = subsampled_counts.plot(kind='bar', title='Train Set Target Distribution')\n",
    "ax.tick_params(axis='x', rotation=45)# Rotate x-axis labels\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search CV - Sklearn\n",
    "#### Use standard hyperparameters to find most suitable algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_search = {\n",
    "    \"DecisionTreeRegressor\": DecisionTreeRegressor(random_state=101),\n",
    "    \"RandomForestRegressor\": RandomForestRegressor(random_state=101),\n",
    "    \"ExtraTreesRegressor\": ExtraTreesRegressor(random_state=101),\n",
    "    \"AdaBoostRegressor\": AdaBoostRegressor(random_state=101),# algorithm='SAMME'\n",
    "}\n",
    "\n",
    "params_search = {\n",
    "    \"DecisionTreeRegressor\": {},\n",
    "    \"RandomForestRegressor\": {},\n",
    "    \"ExtraTreesRegressor\": {},\n",
    "    \"AdaBoostRegressor\": {},\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train.unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick GridSearch CV - Binary Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, r2_score\n",
    "\n",
    "search = HyperparameterOptimizationSearch(models=models_search, params=params_search)\n",
    "search.fit(X_train, y_train,\n",
    "           scoring =  make_scorer(r2_score),\n",
    "           n_jobs=-1, cv=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_summary, grid_search_pipelines = search.score_summary(sort_by='mean_score')\n",
    "grid_search_summary "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do an extensive search on the most suitable algorithm to find the best hyperparameter configuration.\n",
    "Define model and parameters, for Extensive Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "models_search = {\n",
    "    \"RandomForestRegressor\": RandomForestRegressor(random_state=101),\n",
    "}\n",
    "\n",
    "# Documentation to help on hyperparameter list:\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html\n",
    "\n",
    "# We will not conduct an extensive search, since the focus\n",
    "# is on how to combine all knowledge in an applied project.\n",
    "# In a workplace project, you may spend more time in this step\n",
    "params_search = {\n",
    "    \"RandomForestRegressor\": {\n",
    "        'model__n_estimators': [100,150,200],\n",
    "        'model__max_depth': [None, 10, 20,],\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extensive GridSearch CV - Binary Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, make_scorer\n",
    "search = HyperparameterOptimizationSearch(models=models_search, params=params_search)\n",
    "search.fit(X_train, y_train, \n",
    "           scoring =  make_scorer(r2_score,),\n",
    "           n_jobs=-1, cv=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_summary, grid_search_pipelines = search.score_summary(sort_by='mean_score')\n",
    "grid_search_summary "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get best model name programmatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = grid_search_summary.iloc[0,0]\n",
    "best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters for best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_parameters = grid_search_pipelines[best_model].best_params_\n",
    "best_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the best clf pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_reg = grid_search_pipelines[best_model].best_estimator_\n",
    "print(pipeline_reg['feat_selection'].get_support())\n",
    "pipeline_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assess feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert X_train to a pandas DataFrame\n",
    "X_train_df = pd.DataFrame(X_train)\n",
    "\n",
    "# Now use the .tail() method\n",
    "X_train_df.tail()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* With the current model, we can assess with .features_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming X_train is your NumPy array ()\n",
    "#X_train_df = pd.DataFrame(X_train_original)\n",
    "print(X_train.shape)\n",
    "print(X_train_df.shape)\n",
    "\n",
    "# Now you can access the columns attribute \n",
    "columns = X_train_df.columns\n",
    "print(pipeline_reg)\n",
    "print(' next  ')\n",
    "print(columns)\n",
    "\n",
    "# Access feature importances from the feature selection step\n",
    "feat_selector = pipeline_reg.named_steps['feat_selection'].estimator_\n",
    "feat_selector_importances = feat_selector.feature_importances_\n",
    "\n",
    "print(\"feat selector:\",feat_selector)\n",
    "print(\"Feature importances from SelectFromModel step:\", feat_selector_importances)\n",
    "\n",
    "\n",
    "# create DataFrame to display feature importance\n",
    "df_feature_importance = (pd.DataFrame(data={\n",
    "    # 'Feature': columns[pipeline_reg['feat_selection'].get_support()],\n",
    "    'Feature': columns,\n",
    "    # 'Importance': pipeline_reg['model'].feature_importances_\n",
    "    'Importance':feat_selector_importances})\n",
    "    .sort_values(by='Importance', ascending=False))\n",
    "                                    \n",
    "\n",
    "# re-assign best_features order\n",
    "best_features = df_feature_importance['Feature'].to_list()\n",
    "\n",
    "# Most important features statement and plot\n",
    "print(f\"* These are the {len(best_features)} most important features in descending order. \"\n",
    "      f\"The model was trained on them: \\n{df_feature_importance['Feature'].to_list()}\")\n",
    "\n",
    "df_feature_importance.plot(kind='bar', x='Feature', y='Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Pipeline on Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "def reg_performance(X_train, y_train, X_test, y_test, pipeline):\n",
    "    print(\"#### Train Set #### \\n\")\n",
    "    y_train_pred = pipeline.predict(X_train)\n",
    "    print(\"Mean Squared Error (Train):\", mean_squared_error(y_train, y_train_pred))\n",
    "    print(\"R2 Score (Train):\", r2_score(y_train, y_train_pred))\n",
    "\n",
    "    print(\"\\n#### Test Set ####\\n\")\n",
    "    y_test_pred = pipeline.predict(X_test)\n",
    "    print(\"Mean Squared Error (Test):\", mean_squared_error(y_test, y_test_pred))\n",
    "    print(\"R2 Score (Test):\", r2_score(y_test, y_test_pred))\n",
    "\n",
    "    # Plot Actual vs. Predicted for training data\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.scatter(y_train, y_train_pred, alpha=0.5)\n",
    "    plt.plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], '--', color='red')\n",
    "    plt.xlabel('Actual')\n",
    "    plt.ylabel('Predicted')\n",
    "    plt.title('Actual vs. Predicted (Training)')\n",
    "    \n",
    "    # Plot Actual vs. Predicted for test data\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.scatter(y_test, y_test_pred, alpha=0.5)\n",
    "    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], '--', color='red')\n",
    "    plt.xlabel('Actual')\n",
    "    plt.ylabel('Predicted')\n",
    "    plt.title('Actual vs. Predicted (Test)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# Suppress undefined metric warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation: We cross check with metrics defined at ML business case\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_performance(X_train=X_train, y_train=y_train,\n",
    "                 X_test=X_test, y_test=y_test,\n",
    "                 pipeline=pipeline_reg,\n",
    "                )\n",
    "\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Refit pipeline with best features\n",
    "### Refit ML Pipeline and Resampling\n",
    "In theory, a pipeline fitted **using only the most important features** should give the same result as the one fitted with **all variables and feature selection**.\n",
    "\n",
    "### Rewrite ML pipeline for Data Cleaning and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New Pipeline for DataCleaning And FeatureEngineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature_engine.encoding import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "\n",
    "def PipelineDataCleaningAndFeatureEngineering():\n",
    "    pipeline_base = Pipeline([\n",
    "    \n",
    "        # Scale numerical features\n",
    "        (\"Scaler\", StandardScaler()),  \n",
    "        (\"feature_selection\", SelectFromModel(RandomForestRegressor())),\n",
    "    ])\n",
    "\n",
    "    return pipeline_base\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rewrite ML Pipeline for Modelling\n",
    "Function for Pipeline optmisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline Optimization: Model\n",
    "def PipelineReg(model):\n",
    "    pipeline_base = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"model\", model),\n",
    "    ])\n",
    "\n",
    "    return pipeline_base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Train Test Set, considering only with best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into features (X) and target variable (y)\n",
    "X = df.drop(['SalePrice'], axis=1)\n",
    "y = df['SalePrice']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split\n",
    "X_train, X_test, y_train, y_test,  = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=101,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle Target Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_data_cleaning_feat_eng = PipelineDataCleaningAndFeatureEngineering()\n",
    "\n",
    "X_train = pipeline_data_cleaning_feat_eng.fit_transform(X_train, y_train)\n",
    "X_test = pipeline_data_cleaning_feat_eng.transform(X_test)\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check Train Set Target distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set figure size\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "np.random.seed(101)\n",
    "\n",
    "# Plot bar chart\n",
    "counts = y_train.value_counts()\n",
    "# Subsample the counts\n",
    "subsampled_counts = counts.sample(n=min(20, len(counts)))  \n",
    "\n",
    "subsampled_counts.plot(kind='bar', title='Train Set Target Distribution')\n",
    "\n",
    "# Set title and labels\n",
    "plt.title('Train Set Target Distribution')\n",
    "plt.xlabel('Target Value')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "# Rotate x-axis labels\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Adjust layout to prevent overlapping\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use NearMiss to balance Train Set target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import NearMiss\n",
    "\n",
    "# Define the NearMiss undersampler\n",
    "undersampler = NearMiss(version=1, n_neighbors=1)\n",
    "\n",
    "# Apply NearMiss undersampling to the dataset\n",
    "X_resampled, y_resampled = undersampler.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check Train Set Target distribution after NearMiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set figure size\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "np.random.seed(101)\n",
    "\n",
    "# Plot bar chart\n",
    "counts = y_train.value_counts()\n",
    "# Subsample the counts\n",
    "subsampled_counts = counts.sample(n=min(20, len(counts)))  \n",
    "\n",
    "subsampled_counts.plot(kind='bar', title='Train Set Target Distribution')\n",
    "\n",
    "# Set title and labels\n",
    "plt.title('Train Set Target Distribution')\n",
    "plt.xlabel('Target Value')\n",
    "plt.ylabel('Count')\n",
    "\n",
    "# Rotate x-axis labels\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Adjust layout to prevent overlapping\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search CV: Sklearn\n",
    "Using the most suitable model from the last section and its best hyperparameter configuration.\n",
    "\n",
    "We are using the same model from the last GridCV search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_search  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the best parameters from the last GridCV search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to type in manually since the hyperparameter values have to be a list. The previous dictionary is not in this format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_search = {\n",
    "    'RandomForestRegressor': {\n",
    "        'model__n_estimators': [100, 300, 500],\n",
    "        'model__max_depth': [None, 10, 30],\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GridSearch CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.metrics import make_scorer, r2_score\n",
    "\n",
    "quick_search = HyperparameterOptimizationSearch(\n",
    "    models=models_search, params=params_search)\n",
    "quick_search.fit(X_train, y_train,\n",
    "                 scoring=make_scorer(r2_score, ),\n",
    "                 n_jobs=-1, cv=3)\n",
    "\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_summary, grid_search_pipelines = quick_search.score_summary(sort_by='mean_score')\n",
    "grid_search_summary "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the best clf pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_model = grid_search_summary.iloc[0, 0]\n",
    "pipeline_reg = grid_search_pipelines[best_model].best_estimator_\n",
    "pipeline_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assess feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"best_features:\", best_features)\n",
    "print(\"feature_importances:\", pipeline_reg['model'].feature_importances_)\n",
    "print(\"Length of best_features:\", len(best_features))\n",
    "print(\"Length of feature_importances:\", len(pipeline_reg['model'].feature_importances_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create DataFrame to display feature importance\n",
    "df_feature_importance = (pd.DataFrame(data={\n",
    "    'Feature': columns.tolist(),\n",
    "    'Importance': pipeline_reg['model'].feature_importances_})\n",
    "    .sort_values(by='Importance', ascending=False)\n",
    ")\n",
    "\n",
    "\n",
    "# Most important features statement and plot\n",
    "print(f\"* These are the {len(best_features)} most important features in descending order. \"\n",
    "      f\"The model was trained on them: \\n{df_feature_importance['Feature'].to_list()}\")\n",
    "\n",
    "df_feature_importance.plot(kind='bar', x='Feature', y='Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Pipeline on Train and Test Sets\n",
    "Evaluation: We cross-check with metrics defined in the ML business case.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_performance(X_train=X_train, y_train=y_train,\n",
    "                X_test=X_test, y_test=y_test,\n",
    "                pipeline=pipeline_reg,\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Push files to Repo\n",
    "We will generate the following files\n",
    "\n",
    "* Train set\n",
    "* Test set\n",
    "* Data cleaning and Feature Engineering pipeline\n",
    "* Modeling pipeline\n",
    "* features importance plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "version = 'v1'\n",
    "file_path = f'outputs/ml_pipeline/predict_saleprice/{version}'\n",
    "\n",
    "try:\n",
    "    os.makedirs(name=file_path)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "# X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm not sure when or how X_train became a numpy array. but I used the pd.DataFrame() method to convert it back into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert X_train to a DataFrame\n",
    "X_train_df = pd.DataFrame(X_train)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "X_train_df.to_csv(f\"{file_path}/X_train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df.to_csv(f\"{file_path}/X_train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.to_csv(f\"{file_path}/y_train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Set\n",
    "* note that the variables are transformed already in X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert X_test to a DataFrame\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "\n",
    "# Now you can use DataFrame methods like head()\n",
    "X_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test_df.shape)\n",
    "X_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_df.to_csv(f\"{file_path}/X_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.to_csv(f\"{file_path}/y_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML Pipelines: Data Cleaning and Feat Eng pipeline and Modelling Pipeline\n",
    "We will save 2 pipelines:\n",
    "\n",
    "* Both should be used in conjunction to predict Live Data.\n",
    "* To predict on Train Set, Test Set we use only pipeline_reg, since the data is already processed.\n",
    "Pipeline responsible for Data Cleaning and Feature Engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_data_cleaning_feat_eng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(value=pipeline_data_cleaning_feat_eng ,\n",
    "            filename=f\"{file_path}/clf_pipeline_model.pkl\")\n",
    "joblib.dump(value=pipeline_reg ,\n",
    "            filename=f\"{file_path}/clf_pipeline_predict.pkl\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature_importance.plot(kind='bar',x='Feature',y='Importance', figsize=(3, 6))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature_importance.plot(kind='bar', x='Feature', y='Importance', figsize=(3,6))\n",
    "plt.savefig(f'{file_path}/features_importance.png', bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
